remotes::install_github("jacobbien/litr-project", subdir = "litr")
rm(list=ls())
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
?case_when
library(tidyverse)
p <- c(4/16, 3/16, 2/16, 1/16, 3/16, 2/16, 1/16)
sum(p)
x <- c(0:3, -1:-3)
x
x %*% p
(x - 0)^2 %*% p
sqrt((x - 0)^2 %*% p)
2.5*16
500*1/2400 + 4*4/2400 + 10*10/2400
library(MASS)
fractions(500*1/2400 + 4*4/2400 + 10*10/2400)
77*8
x <- c(500, 4, 10, 0)
p <- c(1/2400, 4/2400, 10/2400, 2385/2400)
sum(p)
(x - 77/300)^2 %*% p
sqrt((x - 77/300)^2 %*% p)
x %*% p
77/300*5
x <- c(-1000, 0, 1000, 2000, 3000)
p <- c(0.13, 0.15, .24, 0.35, 0.13)
x %*% p
sum(p)
(1 - .45)^10
1 - (1 - .45)^10 - 10*.45*(1 - .45)^9
?binomcdf
?rbinom
pbinom(q=5, size=10, prob=0.45)
pbinom(q=0, size=10, prob=0.45)
pbinom(q=1, size=10, prob=0.45)
(1 - .45)^10 + 10*.45*(1 - .45)^9
dbinom(x=3, size=5, prob=0.25)
qnorm(p=0.7, mean=125, sd=6.5)
1 - .7^5 - 5*.3*.7^4
?rgeom
(1 - .19)^4*.19
1/.19
1 - pgeom(10, .19)
4*.6^3*.4 + .6^4
15*.6
sqrt(15*.6*.4)
5400+3070+2200-1720
5400+3070+2200-1720-6033
81346 - 75323
564-69
library(cssr)
data <- genClusteredData(n = 200, # Sample size
p = 100, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 50:55)
# Wrapper functions (easy!)
n_test <- 50
n <- 200
p <- 100
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
# cssPredict(X, y, testx, clusters)
cssPredict(X, y, testx, clusters)
n_test <- 50
n <- 200
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
inds <- 1:round(n/2)
lambda <- getLassoLambda(X[setdiff(1:n, inds), ], y[setdiff(1:n, inds)])
lambda <- getLassoLambda(X, y)
lambda
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
inds <- 1:round(n/2)
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
nrow(X)
n
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting=w,
cutoff=c, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y
)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting=w, cutoff=c
# , min_num_clusts=1
# , max_num_clusts=3
)
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
results |> print.cssr(cutoff=c, min_num_clusts=1, max_num_clusts=3)
print(results)
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting=w, cutoff=c, min_num_clusts=1, max_num_clusts=3)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
library(cssr)
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
# Get a good lambda
lambda <- getLassoLambda(X, y)
# clusters <- list(1:10, 46:40)
# clusters <- 1:10
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
?rowMeans
x_design
rowMeans(x_design)
str(x_design)
str(rowMeans(x_design))
?setdiff
remotes::install_github("jacobbien/litr-project", subdir = "litr",force=TRUE)
4*81
2*3^4
162*2
1750/5000
runif(1)
runif(1)
outer(rep(2, 5), rep(2, 5))
T <- 5
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega(5, 2)
omega_inv <- function(s, c){
return(1/s*(diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)))
}
omega_inv(5, 2)
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
return(1/s*(- matrix(-c/(s + T*c), T, T)))
}
omega_inv(5, 2)
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega_inv <- function(s, c){
return(1/s*(diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)) )
}
omega(5, 2)
omega_inv(5,2)
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T))
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
c <- 2
5 <- s
s <- 5
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
print("intermediate:")
print(ret)
return(1/s*ret)
}
omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-s*c/(1 + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
outer(rep(2, 5), rep(2, 5))
rep(2, 5) %*% rep(2, 5)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega(5, 8) %*% omega_inv(5, 8)
1980.77*2
420/12
69/12
2/3*sqrt(2*.981)*.25 - .25
1/1.7*sqrt(2*.981)*.25 - .25
2/3*sqrt(2*9.81)*.25 - .25
553019/60/60/24
1 + 3.75
6.25v - (1 + 3.75)
6.25 - (1 + 3.75)
6.25 - (.5 + 3.75)
4.5 + 4.25 + 6.25
.5*-99 _ 1644
.5*-99 + 1644
.5*-75 + 2793
2755.5/60/60
1594.5/60/60
4*exp(5)
2*exp(5 + log(2))
2.5*215
8*45+118
2.5*210
library(tidyverse)
library(epipredict)
jhu <- case_death_rate_subset
jhu
canned <- arx_forecaster(epi_data=jhu, outcome="death_rate", predictors=c("case_rate", "death_rate"))
str(canned)
summary(canned)
canned
n <- 100
x <- rnorm(100)
y <- 0.01*x + rnorm(100, sd=sqrt(5))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
n <- 100
x <- rnorm(100)
y <- 0.01*x + rnorm(100, sd=sqrt(2))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
n <- 100
x <- rnorm(100)
y <- 0.1*x + rnorm(100, sd=sqrt(2))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
setwd("/Users/gregfaletto/Documents/GitHub/presto")
source("diabetes.R")
plot_eval_by(sim, "cal_osce_gen_data_app", varying = "age_cutoff") +
xlab("Age cutoff") + ggtitle(NULL) + ylab("Estimated Rare Probability MSE")
tabulate_eval(sim, "cal_osce_gen_data_app", se_format="None",
format_args=list(digits=3))
save_simulation(sim)
?PreDiabetes
144800*8
144800*.8
A <- matrix(c(3, 2, 2, 2), 2, 2)
A
B <- matrix(c(2, 1, 1, 2), 2, 2)
B
eigen(A)
eigen(B)
eigen(A - B)
A - B
A
B
setwd("~/My Drive/Data Science/LaTeX/dissertation2")
getwd()
.8*150
1.2*150
30/170
10.38/1.53
8.86/5.16
2.57/1.62
2.59/1.1
10.4/3.15
8.84/7.56
2.56/2.44
2.59/1.75
.527/.044
2.5/.094
1.03/.033
16.54/.393
.53/.12
2.5/.248
1.04/.093
16.65/1.08
2593.57/7
410/22/9
681/6
5120/2880
5120/2
2592/1296
5120/2592
2592/72
100-78.4
100-20.3
install.packages("simulator")
2+2
851.7*2
851.70 +425/2
221/12
29.44/7.8
360/14
6/7*2593.57
1645/7
(1645 + 371)/7
577.57/7
1.19/(13.95 + 11.25)
1.19*(13.95)/(13.95 + 11.25)
round(1.19*(13.95)/(13.95 + 11.25) + 13.95, 2)
23/(23 + 18)*50.97
round(23/(23 + 18)*50.97, 2)
(21.99 + 18.99)/(18.99 + 16.99 + 21.99)*71.13
(1.89 + 8.99 + 3.99 + 3.49 + .89)/(1.89 + 8.99 + 3.79 + 3.99 + 5.99 + 3.49 + .89+7.99)*38.74
(8.99 + 0.89 + 8.99 + 6.59 + 4.39 + 6.99 + 1.29 + 12.99 + 10.99 + 3.90 + 4.38 + 3.32)
(8.99 + 0.89 + 8.99 + 4.39 + 6.99 + 1.29 + 12.99 + 10.99 + 3.90 + 4.38)/(8.99 + 0.89 + 8.99 + 6.59 + 4.39 + 6.99 + 1.29 + 12.99 + 10.99 + 3.90 + 4.38)*73.71
setwd("~/Documents/GitHub/dataconla2023")
source("pres_figs.R")
?polr
options(contrasts = c("contr.treatment", "contr.poly"))
# options(contrasts = c("contr.treatment", "contr.poly"))
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
library(MASS)
# options(contrasts = c("contr.treatment", "contr.poly"))
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
Freq
housing
housing$Sat
?housing
str(housing$Sat)
housing
head(housing)
summary(housing)
str(housing)
house_model <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
summary(house_model)
house_model <- polr(Sat ~ Infl + Type + Cont, data = housing)
house_model
?predict.polr
?polr
?polr.predict
predict(house_model, housing, type="p")
# options(contrasts = c("contr.treatment", "contr.poly"))
house.plr <- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
house.plr
predict(house.plr, housing, type = "p")
house_plr <- polr(Sat ~ Infl + Type + Cont, data = housing)
predict(house_plr, housing, type = "p")
?predict.glm
predict(house.plr, housing, type = "response")
predict(house.plr, housing, type = "probs")
insurance
?Insurance
str(Insurance)
insurance_model <- polr(Age ~ ., data = Insurance)
predict(insurance_model, Insurance, type="probs")
Insurance
head(Insurance)
library(MASS)
head(Insurance)
str(Insurance)
age_model <- polr(Age ~., data=Insurance)
age_model
predict(age_model, data=Insurance, type="probs")
levels(Insurance$Age)
# Example of creating an ordinal categorical variable from scratch
# Categorical vector of age groupings
ages_vector <- c(">35", "<25", ">35", "25-29", "30-35")
# Specify that they are ordinal variables with the given levels
factor_ages_vector <- factor(ages_vector, order = TRUE,
levels = c("<25", "25-29", "30-35",">35"))
factor_ages_vector
ages_vector
str(Insurance)
age_model <- polr(Age ~., data=Insurance)
age_model
str(Insurance)
summary(Insurance)
library(ordinal)
data(soup)
print("Preparing data...")
resp_levels <- paste("sure", 1:6, sep="_")
soup$SURENESS <- factor(soup$SURENESS, ordered=TRUE)
levels(soup$SURENESS) <- resp_levels
print("Category probabilities:")
print(summary(soup$SURENESS)/length(soup$SURENESS))
model_soup <- polr(SURENESS ~, data=soup)
model_soup <- polr(SURENESS ~., data=soup)
model_soup <- polr(SURENESS ~  PROD + DAY + SOUPTYPE + SOUPFREQ + COLD + EASY +
GENDER + AGEGROUP + LOCATION, data=soup)
?soup
nrow(soup)
